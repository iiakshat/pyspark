{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('DiwaliSales').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.31.208.1:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>DiwaliSales</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1d7943d5b20>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+----------+------+---------+---+--------------+--------------+--------+----------+----------------+------+-------+------+--------+\n",
      "|User_ID|Cust_name|Product_ID|Gender|Age Group|Age|Marital_Status|         State|    Zone|Occupation|Product_Category|Orders| Amount|Status|unnamed1|\n",
      "+-------+---------+----------+------+---------+---+--------------+--------------+--------+----------+----------------+------+-------+------+--------+\n",
      "|1002903|Sanskriti| P00125942|     F|    26-35| 28|             0|   Maharashtra| Western|Healthcare|            Auto|     1|23952.0|  NULL|    NULL|\n",
      "|1000732|   Kartik| P00110942|     F|    26-35| 35|             1|Andhra�Pradesh|Southern|      Govt|            Auto|     3|23934.0|  NULL|    NULL|\n",
      "|1001990|    Bindu| P00118542|     F|    26-35| 35|             1| Uttar Pradesh| Central|Automobile|            Auto|     3|23924.0|  NULL|    NULL|\n",
      "+-------+---------+----------+------+---------+---+--------------+--------------+--------+----------+----------------+------+-------+------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark = spark.read.csv('data.csv', header=True, inferSchema=True)\n",
    "df_pyspark.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = df_pyspark.drop(\"Status\", \"unnamed1\")\n",
    "df_pyspark = df_pyspark.na.drop(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- User_ID: integer (nullable = true)\n",
      " |-- Cust_name: string (nullable = true)\n",
      " |-- Product_ID: string (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Age Group: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Marital_Status: integer (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Zone: string (nullable = true)\n",
      " |-- Occupation: string (nullable = true)\n",
      " |-- Product_Category: string (nullable = true)\n",
      " |-- Orders: integer (nullable = true)\n",
      " |-- Amount: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our goal it to predict the amount spent on Diwali, by looking at the features - Zone, Age, Gender, Marital_Status, Orders,\n",
    "# but for now we will avoid string datatypes.\n",
    "# So, first of all we will group them together:\n",
    "\n",
    "# [Age, Orders, Marital_Status] ----> New Feature ----> Independent Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "assembler = VectorAssembler(inputCols=['Age', 'Orders', 'Marital_Status'], outputCol='Independent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = assembler.transform(df_pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+----------+------+---------+---+--------------+--------------+--------+----------+----------------+------+-------+--------------+\n",
      "|User_ID|Cust_name|Product_ID|Gender|Age Group|Age|Marital_Status|         State|    Zone|Occupation|Product_Category|Orders| Amount|   Independent|\n",
      "+-------+---------+----------+------+---------+---+--------------+--------------+--------+----------+----------------+------+-------+--------------+\n",
      "|1002903|Sanskriti| P00125942|     F|    26-35| 28|             0|   Maharashtra| Western|Healthcare|            Auto|     1|23952.0|[28.0,1.0,0.0]|\n",
      "|1000732|   Kartik| P00110942|     F|    26-35| 35|             1|Andhra�Pradesh|Southern|      Govt|            Auto|     3|23934.0|[35.0,3.0,1.0]|\n",
      "|1001990|    Bindu| P00118542|     F|    26-35| 35|             1| Uttar Pradesh| Central|Automobile|            Auto|     3|23924.0|[35.0,3.0,1.0]|\n",
      "+-------+---------+----------+------+---------+---+--------------+--------------+--------+----------+----------------+------+-------+--------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+\n",
      "| Amount|   Independent|\n",
      "+-------+--------------+\n",
      "|23952.0|[28.0,1.0,0.0]|\n",
      "|23934.0|[35.0,3.0,1.0]|\n",
      "|23924.0|[35.0,3.0,1.0]|\n",
      "+-------+--------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now as we want only two columns: Amount and Independent, so we'll select them.\n",
    "\n",
    "finalized_data = output.select('Amount', 'Independent')\n",
    "finalized_data.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "train_data, test_data = finalized_data.randomSplit([0.8, 0.2])\n",
    "regressor = LinearRegression(featuresCol='Independent', labelCol='Amount')\n",
    "\n",
    "regressor = regressor.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([13.0648, -50.6775, -190.7537])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9210.199368600932"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results = regressor.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+-----------------+\n",
      "|Amount|   Independent|       prediction|\n",
      "+------+--------------+-----------------+\n",
      "| 206.0|[37.0,3.0,0.0]|9541.563293891495|\n",
      "| 370.0|[19.0,4.0,1.0]|9064.966324454372|\n",
      "| 407.0|[33.0,1.0,0.0]|9590.659186643155|\n",
      "| 579.0|[30.0,2.0,1.0]|9310.033716117994|\n",
      "| 582.0|[32.0,4.0,0.0]| 9425.56198135675|\n",
      "| 686.0|[50.0,2.0,0.0]|9762.082739179286|\n",
      "| 738.0|[28.0,2.0,1.0]|9283.904182929731|\n",
      "| 744.0|[28.0,2.0,1.0]|9283.904182929731|\n",
      "| 750.0|[44.0,1.0,1.0]|9543.617927999916|\n",
      "| 760.0|[19.0,4.0,1.0]|9064.966324454372|\n",
      "| 760.0|[29.0,1.0,1.0]|9347.646429087954|\n",
      "| 766.0|[23.0,4.0,0.0]|9307.979082009573|\n",
      "| 770.0|[27.0,4.0,0.0]|9360.238148386095|\n",
      "| 771.0|[25.0,4.0,1.0]|9143.354924019157|\n",
      "| 772.0|[55.0,1.0,0.0]|9878.084051714033|\n",
      "| 785.0|[21.0,3.0,0.0]|9332.527028385402|\n",
      "| 883.0|[29.0,1.0,0.0]|9538.400120266633|\n",
      "| 883.0|[29.0,3.0,0.0]|9437.045161138449|\n",
      "| 942.0|[55.0,2.0,0.0]|9827.406572149941|\n",
      "| 951.0|[20.0,1.0,1.0]|9230.063529740777|\n",
      "+------+--------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_results.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4287.383886815544, 27358423.2776139)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_results.meanAbsoluteError, pred_results.meanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
